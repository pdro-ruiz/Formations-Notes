# Creaci√≥n de soluciones de Computer Vision en Azure

## Azure AI Vision

> üìå **Concepto clave ‚ûú** Azure AI Vision es un servicio de visi√≥n por computadora en Azure que permite analizar im√°genes autom√°ticamente (etiquetado, detecci√≥n de objetos/personas, lectura de texto, etc.).

Azure AI Vision ofrece **capacidades preentrenadas** que se pueden integrar f√°cilmente en apps. Entre sus funciones destacan: generaci√≥n autom√°tica de t√≠tulos y etiquetas, detecci√≥n de objetos y personas con sus *bounding boxes*, an√°lisis de metadatos visuales (formato, colores, puntos de referencia), categorizaci√≥n tem√°tica, eliminaci√≥n de fondo, moderaci√≥n de contenido (v√≠deos o im√°genes con violencia o desnudos), OCR para extraer texto de im√°genes y generaci√≥n de **miniaturas inteligentes** (recortes √≥ptimos). Por ejemplo, con una sola llamada se puede analizar una imagen y obtener las etiquetas o el texto extra√≠do.

* üí° **Aprovisionamiento:** Azure AI Vision puede crearse como recurso individual o como parte de un recurso multiservicio de Azure AI Services.
* ‚ö†Ô∏è **Atenci√≥n:** Para usar funcionalidades avanzadas (reconocimiento de celebridades o monumentos) se debe solicitar acceso limitado.
* ‚úÖ **Respuesta:** El servicio devuelve un objeto JSON estructurado con los resultados solicitados.

**Ejemplo pr√°ctico (Python):** An√°lisis de imagen con t√≠tulo y OCR.

```python
from azure.ai.vision.imageanalysis import ImageAnalysisClient
from azure.ai.vision.imageanalysis.models import VisualFeatures
from azure.core.credentials import AzureKeyCredential

client = ImageAnalysisClient(
    endpoint=os.environ["ENDPOINT"],
    credential=AzureKeyCredential(os.environ["KEY"])
)
result = client.analyze(
    image_url="https://example.com/image.jpg",
    visual_features=[
        VisualFeatures.CAPTION,  # Genera un subt√≠tulo autom√°tico
        VisualFeatures.READ      # Realiza OCR (reconoce texto)
    ],
    gender_neutral_caption=True,
    language="en"
)
print(result.caption)  # T√≠tulo descriptivo de la imagen
```

Este c√≥digo usa el SDK de Azure AI Vision para analizar una imagen, solicitando la generaci√≥n de un *caption* y la lectura de texto. En resumen, **para analizar im√°genes** se puede usar la API REST (Analyze Image) o los SDK oficiales.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© capacidades incluye Azure AI Vision y c√≥mo se accede a ellas?
* ¬øCu√°l es la diferencia entre Azure AI Vision y Azure Face?
* ¬øQu√© formato tiene la respuesta al analizar una imagen con Azure AI Vision?

<br><br><br>
## Generaci√≥n de miniaturas inteligentes y eliminaci√≥n de fondo

> üìå **Concepto clave ‚ûú** *Miniaturas inteligentes* recortan autom√°ticamente la regi√≥n m√°s relevante de una imagen para mostrarla como vista previa; *eliminaci√≥n de fondo* separa el sujeto principal del fondo creando una m√°scara alfa.

Estas funciones mejoran la presentaci√≥n y edici√≥n de im√°genes:

* **Miniaturas inteligentes (Smart Crops):** Crea una versi√≥n reducida de la imagen centrada en el elemento m√°s importante. Sirve para vistas previas atractivas en cat√°logos o webs, sin recortar manualmente cada imagen. Se especifica el ancho y alto deseado y se activa el recorte inteligente (relaciones de aspecto de 0.75 a 1.80).

* **Eliminaci√≥n de fondo:** Azure AI Vision genera una *m√°scara alfa* que distingue el primer plano del fondo. A partir de la m√°scara se puede obtener el sujeto sin fondo (por ejemplo, un PNG con transparencia) y/o el fondo por separado. Esto es √∫til para crear im√°genes sin fondo, mejorar recortes autom√°ticos en e-commerce o integraciones de dise√±o.

> üí° *Tip:* Ambas funcionalidades se activan usando las caracter√≠sticas visuales **SMART\_CROPS** y **REMOVED\_BACKGROUND** en el an√°lisis de imagen (VisualFeatures.SMART\_CROPS, VisualFeatures.OBJECT, etc.). Por ejemplo, con el SDK se puede solicitar Smart Crops junto con otros an√°lisis.

#### Preguntas de autoevaluaci√≥n

* ¬øPara qu√© sirve la funci√≥n de miniaturas inteligentes y qu√© par√°metros clave la controlan?
* ¬øC√≥mo obtiene Azure AI Vision la m√°scara alfa al eliminar el fondo?
* Menciona tres casos de uso t√≠picos de la eliminaci√≥n de fondo.

<br><br><br>
## Clasificaci√≥n de im√°genes con Custom Vision

> üìå **Concepto clave ‚ûú** *Custom Vision* permite entrenar modelos personalizados de clasificaci√≥n de im√°genes, asignando etiquetas a objetos o escenas definidas por el usuario.

La **clasificaci√≥n de im√°genes** consiste en asignar una imagen completa a una categor√≠a. En Azure se usa el servicio **Custom Vision** para crear estos modelos desde cero. Para entrenar, se necesitan dos recursos de Azure:

1. Un recurso de entrenamiento (Custom Vision Training) donde se suben y etiquetan las im√°genes.
2. Un recurso de predicci√≥n (Custom Vision Prediction) donde se publica el modelo entrenado para uso en la aplicaci√≥n cliente. Ambos pueden ser un recurso dedicado o parte del recurso multiservicio.

El flujo b√°sico es:

1. **Entrenamiento:** Subir muchas im√°genes etiquetadas por clase.
2. **Publicaci√≥n:** Publicar el modelo en el recurso de predicci√≥n.
3. **Consumo:** Enviar nuevas im√°genes al modelo para obtener etiquetas en tiempo real o por lotes.

> üí° *Importante:* Cuantas m√°s im√°genes por categor√≠a (etiqueta), mejor la precisi√≥n del modelo.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© es Custom Vision y para qu√© se usa?
* ¬øQu√© recursos de Azure son necesarios para entrenar y publicar un modelo de clasificaci√≥n?
* Describe brevemente las etapas de entrenamiento y consumo de un modelo de clasificaci√≥n.

<br><br><br>
## Detecci√≥n de objetos

> üìå **Concepto clave ‚ûú** La *detecci√≥n de objetos* identifica m√∫ltiples objetos en una imagen y devuelve un *bounding box* con coordenadas para cada uno.

A diferencia de la clasificaci√≥n (una sola etiqueta para toda la imagen), la detecci√≥n localiza cada objeto con una etiqueta y un rect√°ngulo delimitador. Cada predicci√≥n de objeto incluye: la etiqueta de la clase (qu√© es el objeto) y la ubicaci√≥n (coordenadas del bounding box).

Para entrenar un detector con Custom Vision:

* Se requieren dos recursos en Azure (entrenamiento y predicci√≥n).
* En el portal de Custom Vision se suben im√°genes y se dibujan rect√°ngulos delimitadores indicando cada objeto.
* Las herramientas soportan el etiquetado manual o semiautom√°tico (etiquetador inteligente). Tambi√©n hay herramientas externas (Azure ML Studio, VoTT) para etiquetar en colaboraci√≥n.
* Los bounding boxes se definen con coordenadas relativas (izquierda, superior, ancho, alto) en decimal respecto a la imagen.

> ‚ö†Ô∏è *Nota:* Aseg√∫rate de definir correctamente los rect√°ngulos (porcentajes) al exportar o usar la API; son cruciales para que el modelo entienda la ubicaci√≥n.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© diferencia existe entre clasificaci√≥n de im√°genes y detecci√≥n de objetos?
* ¬øQu√© datos incluye la predicci√≥n de un objeto detectado?
* ¬øC√≥mo se representan los *bounding boxes* en Custom Vision?

<br><br><br>
## Detecci√≥n y an√°lisis de rostros

> üìå **Concepto clave ‚ûú** Azure AI Vision puede detectar personas en im√°genes (con bounding boxes), mientras que **Azure Face** es un servicio especializado que ofrece detecci√≥n avanzada y reconocimiento facial.

**Azure AI Vision (generalista):** Con VisualFeatures.PEOPLE, detecta personas devolviendo coordenadas y nivel de confianza. Sirve para contar personas o an√°lisis de presencia, pero no brinda detalles faciales (edad/g√©nero han sido retirados por dise√±o responsable).

**Azure Face (especializado):** Ofrece detecci√≥n de caras (bounding box), an√°lisis detallado (posici√≥n de cabeza, emociones, gafas, puntos clave‚Ä¶) y funciones de comparaci√≥n y reconocimiento de identidad. Para usar verificaci√≥n o identificaci√≥n de personas √∫nicas se requiere **acceso limitado**. Azure Face incluye:

* **Detecci√≥n de caras:** Retorna un ID √∫nico para cada cara detectada y su bounding box.
* **An√°lisis de rasgos:** Indica atributos como rotaci√≥n de cabeza 3D, uso de accesorios (gafas, gorro), calidad para reconocimiento (bajo/alto), coordenadas clave (ojos, nariz‚Ä¶).
* **Comparaci√≥n de caras:** Determina si dos im√°genes corresponden a la misma persona.
* **Reconocimiento facial:** Identifica o verifica una cara contra un grupo entrenado de personas (PersonGroup).
* **Detecci√≥n de vivacidad:** Comprueba si la imagen proviene de una fuente real (v√≠deo en vivo) para prevenir suplantaciones.

> ‚ö†Ô∏è *Responsabilidad:* El tratamiento de datos faciales es sensible (identificadores biom√©tricos). Debe considerarse privacidad (cumplir GDPR), transparencia (informar al usuario) y equidad (datos diversos para evitar sesgos). Por √©tica, Azure Face ya no predice edad o g√©nero del sujeto.

#### Preguntas de autoevaluaci√≥n

* ¬øC√≥mo difiere Azure AI Vision de Azure Face en el manejo de im√°genes con personas?
* ¬øQu√© informaci√≥n ofrece el an√°lisis de rasgos faciales de Azure Face?
* ¬øQu√© pasos implica entrenar un modelo de reconocimiento facial con Azure Face?

<br><br><br>
## OCR: Leer texto en im√°genes

> üìå **Concepto clave ‚ûú** El OCR (Reconocimiento √ìptico de Caracteres) con Azure AI Vision *Read API* extrae texto de im√°genes (se√±ales, documentos, recibos) de forma autom√°tica.

Azure AI Vision incluye la caracter√≠stica **READ** para leer texto de im√°genes. Es una operaci√≥n s√≠ncrona que devuelve en una sola llamada cadenas de texto extra√≠das, organizadas en bloques, l√≠neas y palabras. El servicio compara varios casos de uso (se√±ales, notas, carteles) y puede manejar documentos impresos o manuscritos.

Para usarlo:

* Se invoca `client.analyze` con la caracter√≠stica `VisualFeatures.READ`.
* En la llamada REST se usa el endpoint `imageanalysis:analyze?features=Read` con la URL o bytes de la imagen.

**Ejemplo (Python):**

```python
result = client.analyze(
    image_url="https://example.com/receipt.jpg",
    visual_features=[VisualFeatures.READ]
)
```

Este c√≥digo devuelve en `result` un objeto que contiene el texto reconocido en formato estructurado.

**Ejemplo (REST curl):**

```bash
curl -X POST "https://<endpoint>/computervision/imageanalysis:analyze?features=Read&language=en" \
  -H "Ocp-Apim-Subscription-Key: <tu_clave>" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com/image.jpg"}'
```

El resultado JSON incluye jerarqu√≠a: **Bloques ‚Üí L√≠neas ‚Üí Palabras**, cada palabra con su texto, posici√≥n (pol√≠gono) y confianza.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© estructura sigue la respuesta del OCR en Azure AI Vision?
* ¬øC√≥mo se solicita el servicio de OCR usando Python y usando REST?
* ¬øPara qu√© casos es m√°s adecuado usar OCR y qu√© alternativa de Azure existe para documentos complejos?

<br><br><br>
## Azure Video Indexer

> üìå **Concepto clave ‚ûú** *Azure Video Indexer* es un servicio que extrae insights avanzados de archivos de video (etiquetas, personajes, transcripci√≥n, etc.) de forma autom√°tica.

Este servicio analiza v√≠deos completos y proporciona metadatos √∫tiles: detecci√≥n facial (personas en pantalla, requiere acceso limitado), OCR en video, transcripci√≥n de audio con identificaci√≥n de locutores, an√°lisis de temas y sentimientos, etiquetas de objetos o acciones, moderaci√≥n de contenido y segmentaci√≥n por escenas. Todo se puede manejar desde el portal de Video Indexer o mediante API.

Entre sus opciones avanzadas est√° la creaci√≥n de modelos personalizados para: reconocimiento facial espec√≠fico, vocabulario especializado (mejorar transcripci√≥n de jerga), identificaci√≥n de marcas o logos personalizados. Tambi√©n ofrece **widgets** incrustables para mostrar an√°lisis de v√≠deo en tus propias aplicaciones.

**Integraci√≥n mediante API REST:**

* Se obtiene un token de acceso con una llamada GET al endpoint de autenticaci√≥n:

```bash
curl -X GET "https://api.videoindexer.ai/Auth/<ubicaci√≥n>/Accounts/<accountId>/AccessToken?allowEdit=true" \
  -H "Ocp-Apim-Subscription-Key: <tu_clave>"
```

* Con ese token se puede, por ejemplo, listar los videos de la cuenta:

```bash
curl -X GET "https://api.videoindexer.ai/<ubicaci√≥n>/Accounts/<accountId>/Videos?accessToken=<token>"
```

Esta API permite automatizar tareas como subir v√≠deos, iniciar an√°lisis, consultar resultados y gestionar personalizaciones (logos, nombres propios, etc.).

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© funcionalidades generales ofrece Azure Video Indexer? Menciona al menos tres.
* ¬øC√≥mo obtienes un token de acceso para usar la API de Video Indexer?
* ¬øPara qu√© sirven los widgets de Video Indexer?

<br><br><br>
## IA Generativa con Visi√≥n

> üìå **Concepto clave ‚ûú** Los modelos multimodales (texto + imagen) de Azure AI Foundry permiten crear aplicaciones conversacionales que entienden im√°genes y texto simult√°neamente.

Con Azure AI Foundry se pueden implementar chatbots que procesen entrada visual. Modelos como **Phi-4-multimodal** u **OpenAI GPT-4o** admiten prompts que combinan texto e im√°genes. En el Azure Portal existe un √°rea de pruebas donde se puede:

* Subir una imagen y escribir texto en el prompt.
* Obtener una respuesta donde el modelo interpreta ambos.

Para integrar esto en una app:
Se env√≠a una solicitud al endpoint del modelo con un JSON que incluya mensajes con tipo texto e imagen. Por ejemplo:

```json
{
  "messages": [
    {"role": "system", "content": "Eres un asistente √∫til."},
    {
      "role": "user",
      "content": [
        {"type": "text", "text": "Describe esta imagen:"},
        {"type": "image_url", "image_url": {"url": "https://example.com/foto.jpg"}}
      ]
    }
  ]
}
```

En respuesta, el modelo usa tanto el contenido visual como textual para generar su respuesta. Se puede acceder al modelo mediante la API de OpenAI o el cliente de Azure AI, usando SDKs como Python.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© es un modelo multimodal y c√≥mo se usa en Azure AI Foundry?
* ¬øQu√© contiene el JSON enviado a un modelo multimodal para interpretar texto e imagen?
* Nombra dos modelos compatibles con Azure AI Foundry para entrada visual.

<br><br><br>
## Generaci√≥n de im√°genes con Azure OpenAI (DALL¬∑E)

> üìå **Concepto clave ‚ûú** *DALL¬∑E* es un modelo de Azure OpenAI que genera im√°genes originales a partir de descripciones en texto.

El servicio Azure OpenAI permite generar gr√°ficos con lenguaje natural. DALL¬∑E crea nuevas im√°genes (no s√≥lo busca existencias) bas√°ndose en el prompt textual. Por ejemplo, el texto ‚ÄúUna ardilla en una motocicleta‚Äù produce una imagen √∫nica acorde a esa descripci√≥n.

**C√≥mo usarlo:** Desde Azure OpenAI (p.ej. Azure AI Studio) se puede ajustar resoluci√≥n (p.ej. 1024√ó1024), estilo (vivid o natural) y calidad. Mediante la API REST se env√≠a una solicitud POST con JSON que incluye:

* `prompt`: descripci√≥n en texto.
* `n`: n√∫mero de im√°genes (DALL¬∑E 3 solo admite n=1).
* `size`: resoluci√≥n.
* Opcionales: `quality` (‚Äústandard‚Äù o ‚Äúhd‚Äù), `style` (‚Äúvivid‚Äù o ‚Äúnatural‚Äù).

```json
{
  "prompt": "Un tej√≥n con esmoquin",
  "n": 1,
  "size": "1024x1024",
  "quality": "hd",
  "style": "vivid"
}
```

La respuesta es s√≠ncrona y devuelve la URL de la imagen generada. Por ejemplo:

```json
{
  "created": 1686780744,
  "data": [
    {
      "url": "https://...imagen_generada.png",
      "revised_prompt": "A well-dressed badger in a tuxedo"
    }
  ]
}
```

Donde `url` es la direcci√≥n directa de la imagen PNG y `revised_prompt` muestra c√≥mo DALL¬∑E ajust√≥ el texto interno.

#### Preguntas de autoevaluaci√≥n

* ¬øQu√© par√°metros clave se env√≠an a la API de DALL¬∑E para generar una imagen?
* ¬øQu√© es `revised_prompt` en la respuesta de DALL¬∑E?
* Menciona un caso de uso pr√°ctico para la generaci√≥n de im√°genes con IA.

<br><br><br>
## Glosario

* **Azure AI Vision:** Servicios de visi√≥n artificial en Azure para an√°lisis de im√°genes (detecci√≥n, OCR, descripciones, etc.).
* **Custom Vision:** Servicio de Azure para entrenar y publicar modelos personalizados de clasificaci√≥n de im√°genes.
* **Azure Face:** Servicio especializado en detecci√≥n, an√°lisis y reconocimiento facial con capacidades biom√©tricas.
* **Azure Video Indexer:** Servicio de an√°lisis de v√≠deo que extrae etiquetas, rostros, texto, transcripciones y m√°s de grabaciones multimedia.
* **Smart Crops (miniaturas inteligentes):** Funci√≥n de recorte inteligente de Azure AI Vision que genera miniaturas centradas en el sujeto m√°s relevante.
* **M√°scara alfa:** Imagen en escala de grises que separa primer plano y fondo, usada en eliminaci√≥n de fondo.
* **Bounding Box:** Rect√°ngulo delimitador que rodea un objeto o rostro detectado, definido por coordenadas relativas.
* **OCR (Read API):** Caracter√≠stica de Azure AI Vision para extraer texto de im√°genes y documentos.
* **PersonGroup:** Agrupaci√≥n en Azure Face donde se a√±aden m√∫ltiples im√°genes de un mismo individuo para entrenamiento de reconocimiento facial.
* **V√≠deo Indexer Token:** Token de autenticaci√≥n obtenido mediante API para usar Azure Video Indexer.
* **Multimodal:** Modelos que procesan simult√°neamente texto e imagen como entrada (Azure AI Foundry).
* **DALL¬∑E:** Modelo generativo de Azure OpenAI que crea im√°genes originales a partir de un texto descriptivo.
* **Prompt:** Texto de entrada usado para guiar al modelo generativo (visi√≥n o lenguaje natural).
* **Humano:** Participante del chat o del sistema que provee texto o imagen para el modelo.
* **API REST:** Interfaz de Azure que permite consumir los servicios de Vision y OpenAI mediante HTTP.

<br><br><br>
## Tarjetas de repaso (Flashcards)

| Servicio o Funcionalidad    | Descripci√≥n breve                                                                                    | Palabra clave |
| --------------------------- | ---------------------------------------------------------------------------------------------------- | ------------- |
| **Azure AI Vision**         | Servicio de visi√≥n computacional pre-entrenado de Azure (an√°lisis de im√°genes: detecci√≥n, OCR, etc.) | Vision        |
| **Custom Vision**           | Plataforma para entrenar modelos de clasificaci√≥n de im√°genes con datos propios                      | Clasificaci√≥n |
| **Azure Face**              | Servicio especializado en detecci√≥n y reconocimiento facial con funciones avanzadas                  | Face          |
| **Azure Video Indexer**     | Servicio para analizar v√≠deos y extraer informaci√≥n (rostros, texto, transcripci√≥n, etc.)            | V√≠deo         |
| **Miniaturas inteligentes** | Funci√≥n de Azure Vision para recortar im√°genes enfocando en el elemento principal                    | Miniaturas    |
| **Eliminaci√≥n de fondo**    | Funci√≥n que separa el sujeto del fondo usando una m√°scara alfa                                       | Transparencia |
| **OCR (Read API)**          | Caracter√≠stica que extrae texto de im√°genes o v√≠deos usando Azure AI Vision                          | OCR           |
| **Bounding Box**            | Rect√°ngulo con coordenadas que encierra un objeto o rostro detectado                                 | Caja          |
| **Azure AI Foundry**        | Plataforma de modelos multimodales (texto+imagen) para crear chatbots inteligentes                   | Multimodal    |
| **DALL¬∑E (Azure OpenAI)**   | Modelo de generaci√≥n de im√°genes a partir de texto en Azure OpenAI Service                           | DALL¬∑E        |
